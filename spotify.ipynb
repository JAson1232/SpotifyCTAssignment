{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assume the following in this problem: \n",
    "\n",
    "You have 100 users, who use your main app, which resembles Spotify. \n",
    "You are launching a new feature for an app imitating “Discover weekly”. \n",
    "This new feature will also suggest to the users what songs they can listen to, that they may like.\n",
    "This means that you will be looking at what songs people played in the app and we will suggest new songs to them,\n",
    "in the new feature, based on what we know. The suggested 5 songs may be songs the user has played. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 1 after the day of the launch - Individual choice\n",
    "Each of your 100 users is trying the new Discover feature in your app for the first time, in the first week. The feature will generate songs that he or she may like. You need to generate 5 songs. Assume this is the first week in which you launched your app on the google store. \n",
    " \n",
    "Assume that all users start using the feature on day 1 and no one downloads it later. The 5 songs that will be generated for the first time we pick in the following way:  \n",
    " \n",
    "You already have 100 pre-made playlists, with 50 songs in each. Your task is the following: if you find a playlist that contains 3 songs that the user has listened to already and 3 he has not heard yet, you select this playlist. From this playlist, your algorithm picks any 5 songs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task\n",
    "Write a Python computer program that can simulate Spotify’s “Discover Weekly” as mentioned above.\n",
    "\n",
    "Minimum requirements\n",
    "\n",
    "- Give the pseudocode of your program.\n",
    "\n",
    "- Make a flowchart of your program.\n",
    "\n",
    "- Put comments in your code.\n",
    "\n",
    "- The program generates suggestions for the users of Spotify: a few new songs every few days.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Requiered Libraries Install ( FOR GAUSSIAN NAIVE BAYES AND PANDAS FOR DATAFRAMES )\n",
    "\n",
    "# IMPORTANT!!! PLEASE GO OVER THE README FILE TO MAKE SURE THAT THE NOTEBOOK RUNS SMOOTHLY\n",
    "\n",
    "!pip install pandas\n",
    "!pip install -U scikit-learn\n",
    "!pip install numpy\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import random\n",
    "import array\n",
    "import time\n",
    "import numpy\n",
    "\n",
    "from numpy import arange, average, exp, array, dot\n",
    "from numpy import ndarray\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df : pd.DataFrame = pd.read_csv('spotify-dataset.csv')\n",
    "df_playlists : pd.DataFrame = pd.DataFrame() # Create a new dataframe to store the playlists\n",
    "#df\n",
    "playlists : dict = {}\n",
    "for i in range(0,100): # Loop through the first 100 playlists\n",
    "    df2 : list = []\n",
    "    for j in range(0,50): # Loop through the first 50 songs in each playlist\n",
    "        df2.append(df.sample().values.tolist()[0]) # Get a random song from the dataset\n",
    "    playlists[i] = df2\n",
    "print(playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating basic Dataframes that will be used for the remaining tasks\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "df_train : pd.DataFrame = pd.DataFrame() #Used in task 3\n",
    "#print(df.columns[-9:])\n",
    "\n",
    "\n",
    "\n",
    "def normalize(df): # Normalizing dataframe for better results in task 3\n",
    "    ''' Normalize function turns values into values in the range of 0-1.\n",
    "\n",
    "\n",
    "        Parameters: \n",
    "            df : Pandas dataframe that is to be normalized.\n",
    "\n",
    "        Returns :\n",
    "            result : Pandas datframe with the updated normalized values.\n",
    "\n",
    "    \n",
    "    '''\n",
    "    result : pd.DataFrame = df.copy()\n",
    "    for feature_name in df.columns[-9:]:\n",
    "        max_value : float = df[feature_name].astype(float).max()\n",
    "        min_value : float = df[feature_name].astype(float).min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "\n",
    "\n",
    "    \n",
    "df_norm : pd.DataFrame = normalize(df)\n",
    "\n",
    "print(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Brainer (feat. Justin Bieber, Chance the Rapper & Quavo)', 'Water Under the Bridge', 'Love Incredible (feat. Camila Cabello)', 'Moves Like Jagger - Studio Recording From The Voice Performance', 'Fireball (feat. John Ryan)']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "#Creating a user class where we can define a liked_songs list(for the users preferances) and a categories list to categorize what the user listens to(Task 3)\n",
    "class User: \n",
    "    liked_songs : list = []\n",
    "    categories : list = []\n",
    "    def __init__(self) -> None:\n",
    "        self.liked_songs = []\n",
    "        self.categories = []\n",
    "        \n",
    "    def add_random_song(self): # Adding songs to the liked_songs list\n",
    "        ''' Adds random sampled song from the dataframe to the users liked songs.\n",
    "        \n",
    "            Parameters: \n",
    "                Self: the instance of the class so that the values can be passed to its local liked_songs variable.\n",
    "\n",
    "            Returns: \n",
    "                N/A\n",
    "        \n",
    "        '''\n",
    "        self.liked_songs.append(df.sample().values.tolist()[0]) # Get a random song from the dataset\n",
    "    \n",
    "    def add_random_song_norm(self): #This method adds a normalized song to the users liked songs ( USED ONLY IN TASK 3....ONLY FOR BETTER RESULTS WITH JACCARD SIMILARITY)\n",
    "        '''Adds random normalized sample song from the normalized dataframe to the users liked songs.\n",
    "        \n",
    "            Parameters: \n",
    "                Self: the instance of the class so that the values can be passed to its local liked_songs variable.\n",
    "\n",
    "            Returns: \n",
    "                N/A\n",
    "        \n",
    "        '''\n",
    "        self.liked_songs.append(df_norm.sample().values.tolist()[0])\n",
    "\n",
    "\n",
    "    def find_playlist(self,playlists): \n",
    "        '''' Finds the playlist that meets the following requierments: At least 3 songs in the playlist are songs that the user has NOT listened to and at least 3 are songs that he has listened to.\n",
    "\n",
    "            Parameters :\n",
    "                Self: the instance of the class so that we can access the local variables.\n",
    "                Playlists : the playlist list which contains all the randomly sampled playlists.\n",
    "\n",
    "            Returns : \n",
    "                Playlist : The chosen playlist that meets the requierments of the search.\n",
    "                Commong_songs : The songs that the user had in common with the playlist ( Mostly for debugging purposes and making sure that the method works).\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        common_songs : list = []\n",
    "        for i in playlists:\n",
    "            playlist : list = (playlists[i]) \n",
    "            #print(playlist)\n",
    "            playlistUpdated : list = []\n",
    "            for song in playlist:\n",
    "               # print(song[0])\n",
    "                playlistUpdated.append(song[0])\n",
    "            playlist : list = playlistUpdated\n",
    "            #print(playlist)\n",
    "            counter_exists : int = 0 # counter for the same songs in both playlists\n",
    "            counter_no_exist : int = 0 # counter for the songs that are not in the playlist\n",
    "\n",
    "            for song in self.liked_songs: # Loop through the songs the user listened to\n",
    "                if song[0] in playlist:\n",
    "                    counter_exists+=1\n",
    "                    common_songs.append(song)\n",
    "                else:\n",
    "                    counter_no_exist+=1 \n",
    "            if counter_exists >2 and counter_no_exist >2: \n",
    "                return playlist,common_songs\n",
    "    \n",
    "    def determine_category(self):\n",
    "        '''Determines the category that the user belongs to based on the frequency of pop, rock and techno songs.\n",
    "        \n",
    "            Parameters: \n",
    "                Self: To access the local variables of the instance.\n",
    "\n",
    "            Returns :\n",
    "                Max_category : In the case where the difference between the top two categories is more than 10%, the function returns the cateogry that has the highest frequency.\n",
    "                Max2Cat  : In the case where the difference between the top two categories is less thann 10%, the function returns the top two categories based on frequency. \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        genres : dict = {}\n",
    "        for songs in self.liked_songs:\n",
    "            #print(songs[2])\n",
    "            genre : str = songs[2]\n",
    "            if 'pop' in genre:\n",
    "                genres['pop'] = genres.get('pop',0) + 1\n",
    "            elif 'rock' in genre:\n",
    "                genres['rock'] = genres.get('rock',0) + 1\n",
    "            elif 'techno' in genre:\n",
    "                genres['techno'] = genres.get('techno',0) + 1\n",
    "        maximum : int = 0\n",
    "        max2 : int = 0\n",
    "        max_category : str = \"\"\n",
    "        max2cat : str = \"\"\n",
    "        for i in genres:\n",
    "            if genres[i] >maximum:\n",
    "                maximum =genres[i]\n",
    "                max_category = i\n",
    "            if genres[i]<maximum and genres[i]>max2:\n",
    "                max2 = genres[i]\n",
    "                max2cat = i\n",
    "        \n",
    "        if max2 != 0:\n",
    "            if int((maximum/max2)*10) in range(9,10):\n",
    "                return [max_category,max2cat]\n",
    "            #print(max_category)\n",
    "        return [max_category]\n",
    "\n",
    "\n",
    "            \n",
    "#Task 1: Creating user\n",
    "user1 : User = User()\n",
    "for i in range(0,50):\n",
    "    user1.add_random_song() # Add 50 random songs to the user's listened songs\n",
    "\n",
    "\n",
    "\n",
    "selected_playlist : list = user1.find_playlist(playlists)[0]\n",
    "\n",
    "selected_songs : list  = random.sample(selected_playlist,5)\n",
    "\n",
    "print(selected_songs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 2 - Genres\n",
    "In the second week you will use a different approach: \n",
    "A user opens the app and is looking for new suggestions on “Discover.”  \n",
    " \n",
    "There are three types of music only: pop, rock, and techno.  \n",
    " \n",
    "You want to find which style the user has listened to the most, of those three. Define in your own terms what this should mean. For example, you can say that if the user has listened to 20 rock songs and 2 techno songs, and 3 pop songs, this is a rock music fan. Or you can work with percentages: you can find a user that played 80% techno and 20% pop. You can make your algorithm disregard a difference of 10% and say that if a user played pop 45 percent of the time and rock 50 percent of the time, the difference is small and both styles should be considered equally important to him or her. Outline your scale and assumptions in your work. \n",
    "\n",
    "In the second week, your algorithm should suggest 5 songs again, this time based on the above-mentioned, i.e. based on style. \n",
    " \n",
    "It is possible that the program suggests one song in one week and again the same song in the following week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2 : User = User()\n",
    "for i in range(0,50):\n",
    "    user2.add_random_song() # Add 50 random songs to the user's listened songs\n",
    "\n",
    "#print(user2.liked_songs) # Sample category from song\n",
    "\n",
    "user2.determine_category()\n",
    "df3 : pd.DataFrame = pd.DataFrame()\n",
    "\n",
    "\n",
    "def rec_song(): #recommends songs\n",
    "    '''Recommends songs based on the category that the user has been placed in\n",
    "    \n",
    "        Parameters :\n",
    "            N/A\n",
    "\n",
    "        Returns :\n",
    "            df3 : New dataframe that has the 5 Reccomended songs\n",
    "\n",
    "    '''\n",
    "    if len(user2.determine_category()) > 1: # If there are two categories to reccomend then reccomend 3 songs from the first and then 2 from the second category\n",
    "        df3 : pd.DataFrame = df[df.the_genre_of_the_track == user2.determine_category()[0]].sample(3)\n",
    "        df3.append(df[df.the_genre_of_the_track == user2.determine_category()[1]].sample(2))\n",
    "    else:  # Recommend only one category of songs( 5 songs )\n",
    "        df3 = df[df.the_genre_of_the_track == user2.determine_category()[0]].sample(5)\n",
    "    \n",
    "\n",
    "    return df3\n",
    "rec_song()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 3 - Shifts\n",
    "In the third week after the launch, you want to account for a user’s mood shift. We have a few types of songs: “happy”, “party”, “calming”, and “lounge.” Define in your own algorithm if you think one song can be classified as two of those at the same time.  \n",
    " \n",
    "This week you need to select 5 more songs to suggest to each user, again. If last week the user was playing a lot of songs from one of those types, this week we want to suggest more of the same type. Define, in your own terms what this should mean: if the user listened to 3 “calming” songs, should we provide 3 more without considering other factors? What if he or she also listened to 3 “party” songs and 4 “lounge” style songs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random # Re-importing libraries because random exists in numpy too but we want the random library(I will fix this later on by changing the names of the imported libraries)\n",
    "\n",
    "\n",
    "training_set_inputs : list = [] #Creating basic list for training NB and NN\n",
    "training_set_outputs : list = [[]] # Outputs list for classification\n",
    "\n",
    "N : int = 10 # Number of songs to categorize\n",
    "for i in random.sample(range(0,len(df)), N): # Manually Categorizing N amount of songs for the NB and the NN to use as training sets\n",
    "    training_set_inputs.append(df.loc[i, :].values.tolist()[-9:])\n",
    "    print(df.loc[i, :].values.tolist())\n",
    "    time.sleep(1) # only used because sometimes the print output is not shown so the user does not know the name of the songs he is categorizing\n",
    "    training_set_outputs[0].append(input(\"Please enter a category: #happy = 1 #party = 2 #calming =3# lounge = 4\"))\n",
    "\n",
    "\n",
    "#print(training_set_inputs)\n",
    "\n",
    "tr_in : list = training_set_inputs #Saving these as lists just to have them as both list data types and array data types\n",
    "tr_out : list = training_set_outputs[0]\n",
    "\n",
    "\n",
    "df_train['X'] = training_set_inputs #Addding to data frame just in case they are needed\n",
    "df_train['Y'] = training_set_outputs[0]\n",
    "\n",
    "\n",
    "training_set_outputs = numpy.array(training_set_outputs).T # Turning the training lists into arrays for NN input\n",
    "training_set_inputs = numpy.array(training_set_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Test\n",
      "['Wait', 'Maroon 5', 'pop', 2018, 126, 60, 66, -5, 11, 45, 191, 10, 6, 67]\n"
     ]
    }
   ],
   "source": [
    "sample_test : list = df.loc[555, :].values.tolist()[-9:] # Taking a sample song that we will check predicted category of....saving only the colums that are used to categorize the song\n",
    "print(\"Sample Test\")\n",
    "print(df.loc[555, :].values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nueral network class\n",
    "#Using the numpy random for this class\n",
    "from numpy import random\n",
    "\n",
    "# I dont think it is relevant to this project to explain how the nueral network works or to do docstrings for its functions but everything in this class is just the inner workings of the nueral network\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self):\n",
    "        random.seed(1)\n",
    "        #Size of matrix has to do with inputs(Currently using 9 columns for classification)\n",
    "        self.synaptic_weights = 2 * random.random((9, 1)) - 1\n",
    "\n",
    "\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + exp(-x))\n",
    "\n",
    "\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "\n",
    "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations):\n",
    "        for iteration in range(number_of_training_iterations):\n",
    "            output = self.think(training_set_inputs)\n",
    "            error = training_set_outputs - output\n",
    "            adjustment = dot(training_set_inputs.T, error * self.__sigmoid_derivative(output))\n",
    "            self.synaptic_weights += adjustment\n",
    "\n",
    "  \n",
    "    def think(self, inputs):\n",
    "        return self.__sigmoid(dot(inputs, self.synaptic_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Create NB Model and Nueral Network Instance\n",
    "model : GaussianNB = GaussianNB()\n",
    "neural_network : NeuralNetwork = NeuralNetwork()\n",
    "\n",
    "#Fit the data into the NB Model\n",
    "model.fit(tr_in, tr_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2', 50)]\n",
      "['2']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import collections #Importing this library just to find frequency of predicted categories ( to be used to classify which categories the user mostly listens too)\n",
    "\n",
    "#Creating 3rd user for task 3\n",
    "user3 : User = User()\n",
    "for i in range(0,50):\n",
    "    user3.add_random_song_norm() #This time adding the normalized songs to his liked songs\n",
    "\n",
    "df_nueral : pd.DataFrame = pd.DataFrame(user3.liked_songs)\n",
    "\n",
    "#Predicting the category that the user listens to (using NB model)\n",
    "def predict_categories(liked_songs):\n",
    "    '''Predicts categories using the Guassian Naive Bayes.\n",
    "    \n",
    "        Parameters: \n",
    "            liked_songs : the liked_songs to be classified into categories.\n",
    "        \n",
    "        Returns :\n",
    "            predicted_categories : list of the predictions that the Naive Bayes model made.\n",
    "    \n",
    "    '''\n",
    "    training_set_a : list = []\n",
    "    for song in liked_songs:\n",
    "        training_set_a.append(song[-9:])\n",
    "    \n",
    "    predicted_categories : list = []\n",
    "    for song in training_set_a:\n",
    "        predicted_categories.append(ndarray.tolist(model.predict([song]))[0])\n",
    "    return predicted_categories\n",
    "\n",
    "\n",
    "user3.categories = predict_categories(user3.liked_songs) #Adding the categories to the list\n",
    "\n",
    "# Figuring out which category is the most common\n",
    "Counter : Counter = collections.Counter(user3.categories)\n",
    "chosen_category : list = [max(set(user3.categories), key = user3.categories.count)]\n",
    "most_occur : list = Counter.most_common(4)\n",
    "print(most_occur)\n",
    "\n",
    "#Checkling if the difference between the two categories is less than 10 %\n",
    "if(len(most_occur)>1):\n",
    "    print(100-(most_occur[1][1] / most_occur[0][1]) * 100)\n",
    "    if 100-(most_occur[1][1] / most_occur[0][1]) * 100 <10:\n",
    "        chosen_category = [most_occur[0][0] , most_occur[1][0]]\n",
    "print(chosen_category) # Print the categories that the user relates to\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "#Testing out kmeans clustering for classification\n",
    "kmeans : KMeans = KMeans(n_clusters=4, random_state=0).fit(tr_in)\n",
    "\n",
    "#Adding the combined categories together so that they can be added as parameters for the classification techniques\n",
    "df_norm[\"Raw Text\"] = \"\"\n",
    "\n",
    "#Here we add all the columns of the data we want to use into one as a list, this is because our classification techniques require lists as sample inputs\n",
    "for cols in df.columns[4:13]:\n",
    "    df_norm[\"Raw Text\"] +=  df_norm[cols].astype(str) +\",\" \n",
    "\n",
    "#All of this this just preprocessing the data and making sure it applies to our datatype needs (Aka being floats instead of strings)\n",
    "df_norm[\"Raw Text\"] = df_norm[\"Raw Text\"].apply(lambda x: x.split(\",\"))\n",
    "df_norm[\"Raw Text\"] = df_norm[\"Raw Text\"].apply(lambda x: x[0:9])\n",
    "df_norm[\"Raw Text\"] = df_norm[\"Raw Text\"].apply(lambda x: [float(y) for y in x if y !=''])\n",
    "df_norm[\"Raw Text\"] = df_norm[\"Raw Text\"].apply(lambda x: [float(y) for y in x])\n",
    "df_norm[\"Raw Text\"] = df_norm[\"Raw Text\"].apply(lambda x: [x])\n",
    "\n",
    "#Add columns to the dataframe for each predictions technique for each song in the datafram\n",
    "df['Predicted Category NB'] = df_norm[\"Raw Text\"].apply(model.predict)\n",
    "df['Predicted Category NN'] = df_norm[\"Raw Text\"].apply(neural_network.think)\n",
    "df['Predicted Category Clustering KM'] = df_norm['Raw Text'].apply(kmeans.predict)\n",
    "\n",
    "df #Print dataframe to make sure it looks good\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall after taking a better look at the data we came to the conclusion that Neural Networks, Kmeans clusstering or Naive Bayes are all not valid approaches for this problem. These techniques typically need structured and labeled data for them to give valuable predictions, the kind of data we unfortunaltey do not have. However, we attempted to create that data by personally classifying songs based on our preferances. This turned out to be tedious work and we always fell short on the amount of data we needed. After some reasearch, we found one approach that we believe is the best for this sort of problem. Commonly known as Collaborative Filtering, this technique is actually used in most reccomendation engines. We decided that we would try it out. From the two main approaches, User-based collaborative filtering and item-based collaborative filtering, we opted to go with item-based. The code below is what is used in our final evaluation and solution for task 3. Enjoy:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Experimentation with Jaccard Similarity for Reccomendations\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler : MinMaxScaler = MinMaxScaler()\n",
    "\n",
    "def jaccard_set(list1, list2): #Computing similarity between two lists (These two lists are going to be a song with the liked songs of the user)\n",
    "    \"\"\"Define Jaccard Similarity function for two sets\n",
    "    \n",
    "        Parameters : \n",
    "            list1 : the first list to be compared\n",
    "            list2 : the second list to be compared\n",
    "\n",
    "        Returns :\n",
    "            value : the jaccard similarity index\n",
    "    \"\"\"\n",
    "    intersection : float = len(list(set(list1).intersection(list2)))\n",
    "    union : float = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "\n",
    "\n",
    "# Here we get the similarity between a song and the liked songs of the user \n",
    "def get_jaccard_similarity(user, sample_song : list):\n",
    "    ''' Computes the jaccard similarity between a song and the users liked songs\n",
    "\n",
    "        Parameters : \n",
    "            user : the selected user \n",
    "            sample_song : the sample song that is to be compared\n",
    "    \n",
    "        Returns : \n",
    "            similarity_score = the average similarity score from the song compared to all the users liked songs\n",
    "    \n",
    "    '''\n",
    "    similarity_score : float = 0\n",
    "    for song in user.liked_songs:\n",
    "        similarity_score += jaccard_set(sample_song,song[4:13])\n",
    "    return similarity_score/len(user3.liked_songs) # Our similarity score is the average similarity of each all the songs  \n",
    "\n",
    "\n",
    "df['Jaccard Similarity'] = df_norm['Raw Text'].apply(lambda x: get_jaccard_similarity(user3,x[0])) # Apply the similarity technique for each song to compute how similar it is to the users song taste\n",
    "\n",
    "\n",
    "#Sort the dataframe to get the top 5 songs (the most similar songs) in the first 5 rows\n",
    "dfs : pd.DataFrame = df.sort_values(['Jaccard Similarity'], ascending=[False])\n",
    "dfs.head(5) #Print out the songs that are reccomended based on the users liked songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User has been categorized into the ['2'] category based on the NB prediction\n",
      "------------------------------------------------\n",
      "The suggested songs are : \n",
      "428                        Make Me Like You\n",
      "23                                   Misery\n",
      "543                       Sign of the Times\n",
      "28                            Teenage Dream\n",
      "388    Cold Water (feat. Justin Bieber & M?\n",
      "Name: title, dtype: object\n",
      "------------------------------------------------\n",
      "Happy Listening!! \n"
     ]
    }
   ],
   "source": [
    "#For the sake of possibly not anwsering all of task 3, here are all the requierments:\n",
    "print(\"User has been categorized into the \" + str(chosen_category) + \" category based on the NB prediction\")\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"The suggested songs are : \")\n",
    "print(dfs.head(5)['title'])\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Happy Listening!! \")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d1af5a4960a96d7621722435ce13e2a5fde01041db7fd0603c44397b4f28380"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
